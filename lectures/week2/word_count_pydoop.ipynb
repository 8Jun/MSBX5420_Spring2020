{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 145\ndata 126\nof 111\nand 103\nto 87\na 66\nis 59\nfor 42\nin 41\nare 35\nbig 35\ncan 33\nthat 32\nbe 28\nprocessing 26\nwith 26\nsystem 24\nsystems 24\nApache 22\ncomputing 21\nData 19\nor 19\nlarge 18\nfrom 18\nThe 18\non 18\nas 17\nThis 16\nprocess 15\nit 14\nlike 14\nthis 13\nused 13\nby 13\nBig 12\nmore 11\ninformation 11\nwhich 11\ninto 11\noften 11\ndatasets 11\nwork 9\nstorage 9\nWhile 9\nother 9\nreal-time 8\nprocessed 8\nraw 8\ntypically 8\ndistributed 8\ncluster 8\nat 8\nresources 7\nresults 7\nrequirements 7\nterm 7\nindividual 7\nalso 7\nmost 7\ndatabases 7\nwe 7\nthese 7\nsingle 7\nuseful 7\ninsights 6\ntools 6\ntypes 6\nover 6\nclusters 6\nnot 6\neach 6\nfrequently 6\nquality 6\navailable 6\ningestion 6\nan 6\ndifferent 6\nIn 6\nbeing 6\nusing 6\nprojects 6\nsome 6\nabout 6\nNoSQL 5\ncomputation 5\nmemory 5\ntype 5\nThese 5\nAnother 5\nmight 5\ntheir 5\nanalysis 5\nHadoops 5\ntraditional 5\nmeans 5\nBatch 5\nvisualization 5\nmany 5\nMapReduce 5\ninterface 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# open file in hdfs\\npyhdfs.open(path, mode=mode)\\n\\n# file exist\\npyhdfs.path.exists(path)\\n\\n# list path \\npyhdfs.ls(path)\\n\\n# mkdir\\npyhdfs.mkdir(path)\\n\\n# remove file\\npyhdfs.rmr(path)\\n\\n# copy from hdfs to local\\npyhdfs.get(from_hdfs_path, to_local_path)\\n\\n# copy from local to hdfs\\npyhdfs.put(from_local_path, to_hdfs_path)\\n\\n# copy inside hdfs\\npyhdfs.cp(src_hdfs_path, dest_hdfs_path, **kwargs)\\n\\n# is dir\\npyhdfs.path.isdir(path)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pydoop.hdfs as pyhdfs\n",
    "import os\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = '/usr/lib/hadoop/etc/hadoop'\n",
    "\n",
    "def get_word_counts(data_path):\n",
    "    \"\"\"\n",
    "    return sorted (word, count) list, sort by count\n",
    "    \"\"\"\n",
    "    word_count_dict = {}\n",
    "\n",
    "    with pyhdfs.open(data_path, 'r') as f:\n",
    "        for line in f:\n",
    "            words = line.strip().split()\n",
    "            for word in words:\n",
    "                if word not in word_count_dict:\n",
    "                    word_count_dict[word] = 0\n",
    "                word_count_dict[word] += 1\n",
    "    \n",
    "    sorted_word_counts = sorted(word_count_dict.items(), key = lambda kv:kv[1], reverse = True)\n",
    "    return sorted_word_counts\n",
    "\n",
    "\n",
    "input_data_path = 'hdfs:///user/peigangzhang/big_data_intro.txt'\n",
    "word_counts = get_word_counts(input_data_path)\n",
    "\n",
    "for word, count in word_counts[:100]:\n",
    "    print(word, count)\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "# open file in hdfs\n",
    "pyhdfs.open(path, mode=mode)\n",
    "\n",
    "# file exist\n",
    "pyhdfs.path.exists(path)\n",
    "\n",
    "# list path \n",
    "pyhdfs.ls(path)\n",
    "\n",
    "# mkdir\n",
    "pyhdfs.mkdir(path)\n",
    "\n",
    "# remove file\n",
    "pyhdfs.rmr(path)\n",
    "\n",
    "# copy from hdfs to local\n",
    "pyhdfs.get(from_hdfs_path, to_local_path)\n",
    "\n",
    "# copy from local to hdfs\n",
    "pyhdfs.put(from_local_path, to_hdfs_path)\n",
    "\n",
    "# copy inside hdfs\n",
    "pyhdfs.cp(src_hdfs_path, dest_hdfs_path, **kwargs)\n",
    "\n",
    "# is dir\n",
    "pyhdfs.path.isdir(path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
